{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Spanish to English Translator"
      ],
      "metadata": {
        "id": "28PkoGw4whTA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wspKaPCfCMv3"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os,io\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import tensorflow as tf\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from nltk.translate.bleu_score import corpus_bleu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading the file\n",
        "zip_file = tf.keras.utils.get_file(\n",
        "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
        "    extract=True)\n",
        "\n",
        "file_path = os.path.dirname(zip_file)+\"/spa-eng/spa.txt\""
      ],
      "metadata": {
        "id": "bpdqXTu0CPpl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4ce418e-9fa6-46fe-c80e-a3109ca81cda"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "2638744/2638744 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(path, size=None):\n",
        "    text = io.open(file_path, encoding='UTF-8').read()\n",
        "    lines = text.splitlines()\n",
        "    pairs = [line.split('\\t') for line in lines]\n",
        "    source = np.array([source for target, source in pairs])  # extract source text into a numpy array\n",
        "    target = np.array([target for target, source in pairs])  # extract target text into a numpy array\n",
        "    return source, target\n"
      ],
      "metadata": {
        "id": "33jfZ6LoCc2E"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_sentences, tgt_sentences = load_data(file_path)\n",
        "print(\"Original Sentence:\",src_sentences[40])\n",
        "print(\"Translated Sentence:\",tgt_sentences[40])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEi8Z6ODYVrn",
        "outputId": "bcbe6c1d-e7be-41c0-85d7-1de745fb97d5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Sentence: Abrázame.\n",
            "Translated Sentence: Hug me.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_sentences, tgt_sentences = load_data(file_path)\n",
        "print(\"Original Sentence:\",src_sentences[50])\n",
        "print(\"Translated Sentence:\",tgt_sentences[50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sHseYzrCie_",
        "outputId": "a35edd81-f846-45a2-f254-fcc04ee32b05"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Sentence: Estoy levantado.\n",
            "Translated Sentence: I'm up.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_sentences, tgt_sentences = load_data(file_path)\n",
        "print(\"Original Sentence:\",src_sentences[100])\n",
        "print(\"Translated Sentence:\",tgt_sentences[100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-dZO8KOqwIk",
        "outputId": "e05766f5-0edf-43bf-9f28-b90200ea7933"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Sentence: ¡Salga de aquí!\n",
            "Translated Sentence: Go away!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(src_sentences.shape)\n",
        "print(tgt_sentences.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Jtu9fhKC8L5",
        "outputId": "58c2a79f-e3cc-472d-a075-cf270cdd4374"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(118964,)\n",
            "(118964,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a dataframe\n",
        "df = pd.DataFrame(zip(src_sentences, tgt_sentences), columns=['source_sentence', 'target_sentence'])"
      ],
      "metadata": {
        "id": "eiDFE6YNkqO4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JMrWVForkqFL",
        "outputId": "46c4885a-c146-4929-aa3c-d5f25251aa5f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  source_sentence target_sentence\n",
              "0             Ve.             Go.\n",
              "1           Vete.             Go.\n",
              "2           Vaya.             Go.\n",
              "3         Váyase.             Go.\n",
              "4           Hola.             Hi."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-121dff64-3dd3-4b73-a5e2-6daffb4f6ce7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source_sentence</th>\n",
              "      <th>target_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ve.</td>\n",
              "      <td>Go.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Vete.</td>\n",
              "      <td>Go.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Vaya.</td>\n",
              "      <td>Go.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Váyase.</td>\n",
              "      <td>Go.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hola.</td>\n",
              "      <td>Hi.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-121dff64-3dd3-4b73-a5e2-6daffb4f6ce7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-121dff64-3dd3-4b73-a5e2-6daffb4f6ce7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-121dff64-3dd3-4b73-a5e2-6daffb4f6ce7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-71169b24-1fdf-4701-86cd-9e3cea97ed44\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-71169b24-1fdf-4701-86cd-9e3cea97ed44')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-71169b24-1fdf-4701-86cd-9e3cea97ed44 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lowercase all characters\n",
        "df['source_sentence']=df['source_sentence'].apply(lambda x: x.lower())\n",
        "df['target_sentence']=df['target_sentence'].apply(lambda x: x.lower())"
      ],
      "metadata": {
        "id": "rmGvy3Cwk1KQ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove quotes\n",
        "df['source_sentence']=df['source_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n",
        "df['target_sentence']=df['target_sentence'].apply(lambda x: re.sub(\"'\", '', x))"
      ],
      "metadata": {
        "id": "6iWpc2gck1Bo"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "from string import digits"
      ],
      "metadata": {
        "id": "zmq3WWoVlscr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exclude = set(string.punctuation) # Set of all special characters\n",
        "# Remove all the special characters\n",
        "df['source_sentence']=df['source_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
        "df['target_sentence']=df['target_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"
      ],
      "metadata": {
        "id": "rOHxaVGglOK5"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove all numbers from text\n",
        "remove_digits = str.maketrans('', '', digits)\n",
        "df['source_sentence']=df['source_sentence'].apply(lambda x: x.translate(remove_digits))\n",
        "df['target_sentence']=df['target_sentence'].apply(lambda x: x.translate(remove_digits))\n",
        "\n",
        "df['target_sentence'] = df['target_sentence'].apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
        "\n",
        "# Remove extra spaces\n",
        "df['source_sentence']=df['source_sentence'].apply(lambda x: x.strip())\n",
        "df['target_sentence']=df['target_sentence'].apply(lambda x: x.strip())\n",
        "df['source_sentence']=df['source_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
        "df['target_sentence']=df['target_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))"
      ],
      "metadata": {
        "id": "l2t9xtVBl7tP"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = df['source_sentence']\n",
        "t = df['target_sentence']"
      ],
      "metadata": {
        "id": "obv5207mmqJr"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_sentences = s[500:15000]\n",
        "target_sentences = t[500:15000]"
      ],
      "metadata": {
        "id": "LYqttZ4ICwUx"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(source_sentences.shape)\n",
        "print(target_sentences.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiysqRp9DYwG",
        "outputId": "26b8ed43-f3f5-47ac-f0cb-fa01ee7eb48f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14500,)\n",
            "(14500,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(target_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4y-LIPMZDhnA",
        "outputId": "f858a744-6f39-4c0d-8ef6-df083f3da9c2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Preparation\n",
        "\n",
        "# Tokenization and one-hot encoding\n",
        "tokenizer_source = Tokenizer(oov_token=\"<OOV>\")\n",
        "tokenizer_source.fit_on_texts(source_sentences)\n",
        "source_sequences = tokenizer_source.texts_to_sequences(source_sentences)\n",
        "source_sequences_padded = pad_sequences(source_sequences)\n",
        "\n",
        "tokenizer_target = Tokenizer(oov_token=\"<OOV>\")\n",
        "tokenizer_target.fit_on_texts(target_sentences)\n",
        "target_sequences = tokenizer_target.texts_to_sequences(target_sentences)\n",
        "target_sequences_padded = pad_sequences(target_sequences)"
      ],
      "metadata": {
        "id": "puidDKmT_ZlS"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure <start> and <end> tokens are in the vocabulary\n",
        "if '<start>' not in tokenizer_target.word_index:\n",
        "    tokenizer_target.word_index['<start>'] = len(tokenizer_target.word_index) + 1\n",
        "if '<end>' not in tokenizer_target.word_index:\n",
        "    tokenizer_target.word_index['<end>'] = len(tokenizer_target.word_index) + 1\n"
      ],
      "metadata": {
        "id": "Gm4XubUm_eEZ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the Encoder-Decoder Model\n",
        "latent_dim = 256\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "encoder_embedding = Embedding(len(tokenizer_source.word_index) + 1, latent_dim, mask_zero=True)(encoder_inputs)\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
        "encoder_states = [state_h, state_c]\n"
      ],
      "metadata": {
        "id": "D3jeMYTF_hVc"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decoder\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "decoder_embedding = Embedding(len(tokenizer_target.word_index) + 1, latent_dim, mask_zero=True)(decoder_inputs)\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
        "decoder_dense = Dense(len(tokenizer_target.word_index) + 1, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "metadata": {
        "id": "Ri6hLUD6_kNA"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# Create encoder model\n",
        "encoder_model = Model(encoder_inputs, encoder_states)"
      ],
      "metadata": {
        "id": "kvlW2T3Z_mzc"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create decoder model\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_input = [decoder_state_input_h, decoder_state_input_c]"
      ],
      "metadata": {
        "id": "02qln1g7_pG8"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix: Apply the embedding directly to the decoder inputs\n",
        "decoder_embedding_inference = Embedding(len(tokenizer_target.word_index) + 1, latent_dim, mask_zero=True)(decoder_inputs)\n",
        "decoder_outputs_inference, state_h, state_c = decoder_lstm(\n",
        "    decoder_embedding_inference, initial_state=decoder_states_input\n",
        ")\n",
        "decoder_states_inference = [state_h, state_c]\n",
        "decoder_outputs_inference = decoder_dense(decoder_outputs_inference)\n",
        "\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_input,\n",
        "    [decoder_outputs_inference] + decoder_states_inference\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "1khhShUa_r30"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Training\n",
        "model.compile(optimizer='adam', loss=sparse_categorical_crossentropy, metrics=['accuracy'])\n",
        "model.fit([source_sequences_padded, target_sequences_padded[:, :-1]], target_sequences_padded[:, 1:], epochs=100, batch_size=124)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zB_tDVUK_vXP",
        "outputId": "f2ae84ca-7b3c-45ca-c862-cf8b3685e0f6"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "117/117 [==============================] - 44s 285ms/step - loss: 1.5513 - accuracy: 0.6974\n",
            "Epoch 2/100\n",
            "117/117 [==============================] - 35s 298ms/step - loss: 1.2481 - accuracy: 0.7598\n",
            "Epoch 3/100\n",
            "117/117 [==============================] - 34s 285ms/step - loss: 1.0270 - accuracy: 0.8031\n",
            "Epoch 4/100\n",
            "117/117 [==============================] - 33s 285ms/step - loss: 0.8387 - accuracy: 0.8436\n",
            "Epoch 5/100\n",
            "117/117 [==============================] - 33s 282ms/step - loss: 0.6787 - accuracy: 0.8770\n",
            "Epoch 6/100\n",
            "117/117 [==============================] - 33s 285ms/step - loss: 0.5479 - accuracy: 0.9056\n",
            "Epoch 7/100\n",
            "117/117 [==============================] - 33s 284ms/step - loss: 0.4424 - accuracy: 0.9263\n",
            "Epoch 8/100\n",
            "117/117 [==============================] - 32s 276ms/step - loss: 0.3583 - accuracy: 0.9422\n",
            "Epoch 9/100\n",
            "117/117 [==============================] - 32s 275ms/step - loss: 0.2930 - accuracy: 0.9527\n",
            "Epoch 10/100\n",
            "117/117 [==============================] - 32s 276ms/step - loss: 0.2411 - accuracy: 0.9599\n",
            "Epoch 11/100\n",
            "117/117 [==============================] - 32s 278ms/step - loss: 0.2041 - accuracy: 0.9649\n",
            "Epoch 12/100\n",
            "117/117 [==============================] - 34s 286ms/step - loss: 0.1746 - accuracy: 0.9679\n",
            "Epoch 13/100\n",
            "117/117 [==============================] - 32s 275ms/step - loss: 0.1502 - accuracy: 0.9715\n",
            "Epoch 14/100\n",
            "117/117 [==============================] - 32s 272ms/step - loss: 0.1319 - accuracy: 0.9728\n",
            "Epoch 15/100\n",
            "117/117 [==============================] - 32s 276ms/step - loss: 0.1197 - accuracy: 0.9730\n",
            "Epoch 16/100\n",
            "117/117 [==============================] - 32s 275ms/step - loss: 0.1089 - accuracy: 0.9738\n",
            "Epoch 17/100\n",
            "117/117 [==============================] - 33s 280ms/step - loss: 0.0998 - accuracy: 0.9745\n",
            "Epoch 18/100\n",
            "117/117 [==============================] - 33s 282ms/step - loss: 0.0934 - accuracy: 0.9745\n",
            "Epoch 19/100\n",
            "117/117 [==============================] - 32s 275ms/step - loss: 0.0862 - accuracy: 0.9756\n",
            "Epoch 20/100\n",
            "117/117 [==============================] - 32s 274ms/step - loss: 0.0810 - accuracy: 0.9754\n",
            "Epoch 21/100\n",
            "117/117 [==============================] - 32s 276ms/step - loss: 0.0779 - accuracy: 0.9748\n",
            "Epoch 22/100\n",
            "117/117 [==============================] - 32s 274ms/step - loss: 0.0723 - accuracy: 0.9765\n",
            "Epoch 23/100\n",
            "117/117 [==============================] - 33s 284ms/step - loss: 0.0708 - accuracy: 0.9762\n",
            "Epoch 24/100\n",
            "117/117 [==============================] - 33s 280ms/step - loss: 0.0681 - accuracy: 0.9765\n",
            "Epoch 25/100\n",
            "117/117 [==============================] - 32s 275ms/step - loss: 0.0664 - accuracy: 0.9764\n",
            "Epoch 26/100\n",
            "117/117 [==============================] - 32s 274ms/step - loss: 0.0644 - accuracy: 0.9764\n",
            "Epoch 27/100\n",
            "117/117 [==============================] - 32s 273ms/step - loss: 0.0626 - accuracy: 0.9766\n",
            "Epoch 28/100\n",
            "117/117 [==============================] - 32s 275ms/step - loss: 0.0629 - accuracy: 0.9761\n",
            "Epoch 29/100\n",
            "117/117 [==============================] - 34s 286ms/step - loss: 0.0601 - accuracy: 0.9764\n",
            "Epoch 30/100\n",
            "117/117 [==============================] - 32s 277ms/step - loss: 0.0598 - accuracy: 0.9760\n",
            "Epoch 31/100\n",
            "117/117 [==============================] - 32s 274ms/step - loss: 0.0584 - accuracy: 0.9761\n",
            "Epoch 32/100\n",
            "117/117 [==============================] - 32s 274ms/step - loss: 0.0570 - accuracy: 0.9773\n",
            "Epoch 33/100\n",
            "117/117 [==============================] - 32s 274ms/step - loss: 0.0564 - accuracy: 0.9769\n",
            "Epoch 34/100\n",
            "117/117 [==============================] - 33s 281ms/step - loss: 0.0548 - accuracy: 0.9764\n",
            "Epoch 35/100\n",
            "117/117 [==============================] - 33s 283ms/step - loss: 0.0539 - accuracy: 0.9763\n",
            "Epoch 36/100\n",
            "117/117 [==============================] - 32s 273ms/step - loss: 0.0539 - accuracy: 0.9765\n",
            "Epoch 37/100\n",
            "117/117 [==============================] - 32s 274ms/step - loss: 0.0531 - accuracy: 0.9766\n",
            "Epoch 38/100\n",
            "117/117 [==============================] - 32s 275ms/step - loss: 0.0525 - accuracy: 0.9761\n",
            "Epoch 39/100\n",
            "117/117 [==============================] - 32s 274ms/step - loss: 0.0512 - accuracy: 0.9770\n",
            "Epoch 40/100\n",
            "117/117 [==============================] - 33s 285ms/step - loss: 0.0506 - accuracy: 0.9767\n",
            "Epoch 41/100\n",
            "117/117 [==============================] - 33s 278ms/step - loss: 0.0499 - accuracy: 0.9768\n",
            "Epoch 42/100\n",
            "117/117 [==============================] - 32s 274ms/step - loss: 0.0496 - accuracy: 0.9767\n",
            "Epoch 43/100\n",
            "117/117 [==============================] - 32s 274ms/step - loss: 0.0489 - accuracy: 0.9766\n",
            "Epoch 44/100\n",
            "117/117 [==============================] - 32s 276ms/step - loss: 0.0493 - accuracy: 0.9770\n",
            "Epoch 45/100\n",
            "117/117 [==============================] - 33s 283ms/step - loss: 0.0539 - accuracy: 0.9762\n",
            "Epoch 46/100\n",
            "117/117 [==============================] - 33s 281ms/step - loss: 0.0541 - accuracy: 0.9759\n",
            "Epoch 47/100\n",
            "117/117 [==============================] - 32s 275ms/step - loss: 0.0609 - accuracy: 0.9748\n",
            "Epoch 48/100\n",
            "117/117 [==============================] - 32s 272ms/step - loss: 0.0600 - accuracy: 0.9749\n",
            "Epoch 49/100\n",
            "117/117 [==============================] - 31s 269ms/step - loss: 0.0576 - accuracy: 0.9749\n",
            "Epoch 50/100\n",
            "117/117 [==============================] - 32s 274ms/step - loss: 0.0508 - accuracy: 0.9763\n",
            "Epoch 51/100\n",
            "117/117 [==============================] - 35s 299ms/step - loss: 0.0471 - accuracy: 0.9769\n",
            "Epoch 52/100\n",
            "117/117 [==============================] - 34s 294ms/step - loss: 0.0455 - accuracy: 0.9767\n",
            "Epoch 53/100\n",
            "117/117 [==============================] - 32s 277ms/step - loss: 0.0446 - accuracy: 0.9765\n",
            "Epoch 54/100\n",
            "117/117 [==============================] - 32s 276ms/step - loss: 0.0437 - accuracy: 0.9765\n",
            "Epoch 55/100\n",
            "117/117 [==============================] - 33s 285ms/step - loss: 0.0430 - accuracy: 0.9774\n",
            "Epoch 56/100\n",
            "117/117 [==============================] - 33s 282ms/step - loss: 0.0433 - accuracy: 0.9769\n",
            "Epoch 57/100\n",
            "117/117 [==============================] - 32s 276ms/step - loss: 0.0428 - accuracy: 0.9771\n",
            "Epoch 58/100\n",
            "117/117 [==============================] - 32s 275ms/step - loss: 0.0430 - accuracy: 0.9762\n",
            "Epoch 59/100\n",
            "117/117 [==============================] - 32s 277ms/step - loss: 0.0423 - accuracy: 0.9773\n",
            "Epoch 60/100\n",
            "117/117 [==============================] - 33s 282ms/step - loss: 0.0421 - accuracy: 0.9771\n",
            "Epoch 61/100\n",
            "117/117 [==============================] - 34s 289ms/step - loss: 0.0417 - accuracy: 0.9774\n",
            "Epoch 62/100\n",
            "117/117 [==============================] - 33s 279ms/step - loss: 0.0425 - accuracy: 0.9767\n",
            "Epoch 63/100\n",
            "117/117 [==============================] - 33s 279ms/step - loss: 0.0431 - accuracy: 0.9769\n",
            "Epoch 64/100\n",
            "117/117 [==============================] - 33s 279ms/step - loss: 0.0455 - accuracy: 0.9771\n",
            "Epoch 65/100\n",
            "117/117 [==============================] - 34s 288ms/step - loss: 0.0494 - accuracy: 0.9761\n",
            "Epoch 66/100\n",
            "117/117 [==============================] - 33s 280ms/step - loss: 0.0505 - accuracy: 0.9759\n",
            "Epoch 67/100\n",
            "117/117 [==============================] - 32s 277ms/step - loss: 0.0514 - accuracy: 0.9757\n",
            "Epoch 68/100\n",
            "117/117 [==============================] - 32s 277ms/step - loss: 0.0484 - accuracy: 0.9765\n",
            "Epoch 69/100\n",
            "117/117 [==============================] - 32s 276ms/step - loss: 0.0448 - accuracy: 0.9768\n",
            "Epoch 70/100\n",
            "117/117 [==============================] - 33s 282ms/step - loss: 0.0430 - accuracy: 0.9771\n",
            "Epoch 71/100\n",
            "117/117 [==============================] - 33s 284ms/step - loss: 0.0423 - accuracy: 0.9768\n",
            "Epoch 72/100\n",
            "117/117 [==============================] - 32s 277ms/step - loss: 0.0420 - accuracy: 0.9768\n",
            "Epoch 73/100\n",
            "117/117 [==============================] - 32s 277ms/step - loss: 0.0420 - accuracy: 0.9766\n",
            "Epoch 74/100\n",
            "117/117 [==============================] - 32s 276ms/step - loss: 0.0415 - accuracy: 0.9771\n",
            "Epoch 75/100\n",
            "117/117 [==============================] - 33s 282ms/step - loss: 0.0412 - accuracy: 0.9762\n",
            "Epoch 76/100\n",
            "117/117 [==============================] - 33s 285ms/step - loss: 0.0404 - accuracy: 0.9771\n",
            "Epoch 77/100\n",
            "117/117 [==============================] - 33s 282ms/step - loss: 0.0399 - accuracy: 0.9770\n",
            "Epoch 78/100\n",
            "117/117 [==============================] - 32s 276ms/step - loss: 0.0401 - accuracy: 0.9758\n",
            "Epoch 79/100\n",
            "117/117 [==============================] - 32s 276ms/step - loss: 0.0398 - accuracy: 0.9764\n",
            "Epoch 80/100\n",
            "117/117 [==============================] - 33s 281ms/step - loss: 0.0393 - accuracy: 0.9769\n",
            "Epoch 81/100\n",
            "117/117 [==============================] - 34s 286ms/step - loss: 0.0397 - accuracy: 0.9771\n",
            "Epoch 82/100\n",
            "117/117 [==============================] - 32s 277ms/step - loss: 0.0400 - accuracy: 0.9773\n",
            "Epoch 83/100\n",
            "117/117 [==============================] - 33s 279ms/step - loss: 0.0398 - accuracy: 0.9771\n",
            "Epoch 84/100\n",
            "117/117 [==============================] - 33s 285ms/step - loss: 0.0401 - accuracy: 0.9765\n",
            "Epoch 85/100\n",
            "117/117 [==============================] - 34s 290ms/step - loss: 0.0390 - accuracy: 0.9776\n",
            "Epoch 86/100\n",
            "117/117 [==============================] - 33s 280ms/step - loss: 0.0399 - accuracy: 0.9759\n",
            "Epoch 87/100\n",
            "117/117 [==============================] - 32s 276ms/step - loss: 0.0391 - accuracy: 0.9770\n",
            "Epoch 88/100\n",
            "117/117 [==============================] - 33s 280ms/step - loss: 0.0394 - accuracy: 0.9767\n",
            "Epoch 89/100\n",
            "117/117 [==============================] - 32s 277ms/step - loss: 0.0390 - accuracy: 0.9774\n",
            "Epoch 90/100\n",
            "117/117 [==============================] - 34s 290ms/step - loss: 0.0394 - accuracy: 0.9773\n",
            "Epoch 91/100\n",
            "117/117 [==============================] - 33s 279ms/step - loss: 0.0400 - accuracy: 0.9762\n",
            "Epoch 92/100\n",
            "117/117 [==============================] - 33s 278ms/step - loss: 0.0401 - accuracy: 0.9768\n",
            "Epoch 93/100\n",
            "117/117 [==============================] - 32s 276ms/step - loss: 0.0498 - accuracy: 0.9749\n",
            "Epoch 94/100\n",
            "117/117 [==============================] - 32s 276ms/step - loss: 0.0693 - accuracy: 0.9719\n",
            "Epoch 95/100\n",
            "117/117 [==============================] - 33s 284ms/step - loss: 0.0597 - accuracy: 0.9740\n",
            "Epoch 96/100\n",
            "117/117 [==============================] - 33s 281ms/step - loss: 0.0484 - accuracy: 0.9752\n",
            "Epoch 97/100\n",
            "117/117 [==============================] - 32s 276ms/step - loss: 0.0425 - accuracy: 0.9763\n",
            "Epoch 98/100\n",
            "117/117 [==============================] - 32s 276ms/step - loss: 0.0397 - accuracy: 0.9775\n",
            "Epoch 99/100\n",
            "117/117 [==============================] - 32s 277ms/step - loss: 0.0388 - accuracy: 0.9767\n",
            "Epoch 100/100\n",
            "117/117 [==============================] - 33s 282ms/step - loss: 0.0383 - accuracy: 0.9766\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d6867ab83d0>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Translation Function\n",
        "def translate_sentence(input_sentence):\n",
        "    input_sequence = tokenizer_source.texts_to_sequences([input_sentence])\n",
        "    input_sequence_padded = pad_sequences(input_sequence)\n",
        "\n",
        "    states_value = encoder_model.predict(input_sequence_padded)\n",
        "\n",
        "    target_sequence = np.zeros((1, 1))\n",
        "    target_sequence[0, 0] = tokenizer_target.word_index['<start>']\n",
        "    translated_sentence = ''\n",
        "\n",
        "    while True:\n",
        "        output_tokens, h, c = decoder_model.predict([target_sequence] + states_value)\n",
        "\n",
        "        # Get the index of the most probable token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "\n",
        "        # Handle the case where the sampled token is not in the vocabulary\n",
        "        if sampled_token_index not in tokenizer_target.index_word:\n",
        "            break\n",
        "\n",
        "        sampled_word = tokenizer_target.index_word[sampled_token_index]\n",
        "\n",
        "        if sampled_word == '<end>' or len(translated_sentence.split()) > len(input_sentence.split()) * 2:\n",
        "            break\n",
        "\n",
        "        translated_sentence += sampled_word + ' '\n",
        "\n",
        "        target_sequence = np.zeros((1, 1))\n",
        "        target_sequence[0, 0] = sampled_token_index\n",
        "\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return translated_sentence.strip()\n"
      ],
      "metadata": {
        "id": "8fafq4oo2gli"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "# Prepare a held-out test set and evaluate BLEU score\n",
        "test_source_sentences = ['Tom estaba aterrorizado.']\n",
        "test_target_sentences = ['Tom was terrified.']\n",
        "\n",
        "reference_translations = [sent.split() for sent in test_target_sentences]\n",
        "hypothesis_translations = [translate_sentence(sent).split() for sent in test_source_sentences]\n",
        "\n",
        "bleu_score = corpus_bleu(reference_translations, test_target_sentences)\n",
        "print(f'BLEU Score: {bleu_score}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1IkS7qx_zbm",
        "outputId": "1cc8fe56-60a4-4414-ce93-935c58ad1d28"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "BLEU Score: 0.667278568794606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "input_sentence = \"Estoy levantado.\"  # Replace with your input sentence\n",
        "predicted_translation = translate_sentence(input_sentence)\n",
        "\n",
        "print(f\"Input Sentence: {input_sentence}\")\n",
        "print(f\"Predicted Translation: {predicted_translation}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIHTL2pLeW8m",
        "outputId": "bf93d964-e76e-490b-de45-07ec5fb2dfdd"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Input Sentence: Estoy levantado.\n",
            "Predicted Translation: up up up up up\n"
          ]
        }
      ]
    }
  ]
}